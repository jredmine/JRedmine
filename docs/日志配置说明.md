# 日志配置说明

## 一、配置概述

项目已集成 **Logback + Logstash Encoder**，支持结构化日志（JSON 格式）、日志文件滚动归档，以及根据环境配置不同的日志级别。

## 二、依赖配置

### 2.1 Maven 依赖

已在 `pom.xml` 中添加：

```xml
<dependency>
    <groupId>net.logstash.logback</groupId>
    <artifactId>logstash-logback-encoder</artifactId>
    <version>7.4</version>
</dependency>
```

## 三、日志配置文件

### 3.1 配置文件位置

`src/main/resources/logback-spring.xml`

### 3.2 配置特性

#### 1. 多环境支持

使用 Spring Profile 区分不同环境：
- **dev**：开发环境
- **local**：本地环境
- **prod**：生产环境

#### 2. 日志输出方式

**开发/本地环境（dev/local）**：
- 控制台：彩色格式，便于开发调试
- 文件：JSON 格式，便于日志收集

**生产环境（prod）**：
- 控制台：JSON 格式（便于容器化部署时收集）
- 文件：JSON 格式

#### 3. 日志文件配置

**普通日志文件**：
- 路径：`logs/jredmine.log`
- 滚动策略：按日期和大小
- 单个文件最大：100MB
- 保留天数：30 天
- 总大小限制：10GB

**错误日志文件**：
- 路径：`logs/jredmine-error.log`
- 只记录 ERROR 级别日志
- 单个文件最大：100MB
- 保留天数：90 天（错误日志保留更久）
- 总大小限制：5GB

**文件命名格式**：
- 普通日志：`jredmine-2024-01-15.0.log.gz`
- 错误日志：`jredmine-error-2024-01-15.0.log.gz`

#### 4. 异步日志

使用异步 Appender 提高性能：
- 队列大小：512
- 不丢弃日志（`discardingThreshold=0`）

#### 5. 日志级别配置

**开发/本地环境（dev/local）**：
- Root 级别：INFO
- 项目包（`com.github.jredmine`）：DEBUG
- MyBatis Mapper：DEBUG（显示 SQL）
- Spring 框架：INFO
- MyBatis Plus：INFO

**生产环境（prod）**：
- Root 级别：INFO
- 项目包（`com.github.jredmine`）：INFO
- MyBatis Mapper：WARN（不显示 SQL）
- Spring 框架：WARN
- MyBatis Plus：WARN
- 第三方库：WARN

## 四、结构化日志格式

### 4.1 JSON 日志示例

```json
{
  "@timestamp": "2024-01-15T10:30:45.123+08:00",
  "@version": "1",
  "level": "INFO",
  "logger_name": "com.github.jredmine.service.UserService",
  "message": "用户登录成功",
  "mdc": {
    "userId": "12345",
    "username": "admin",
    "ip": "192.168.1.100"
  },
  "service": "jredmine",
  "host": "server-01",
  "env": "prod",
  "stack_trace": "..."
}
```

### 4.2 日志字段说明

| 字段 | 说明 |
|------|------|
| `@timestamp` | 日志时间戳（Asia/Shanghai 时区） |
| `@version` | 日志格式版本 |
| `level` | 日志级别（DEBUG/INFO/WARN/ERROR） |
| `logger_name` | 日志记录器名称（类名） |
| `message` | 日志消息 |
| `mdc` | 上下文信息（通过 MDC 添加） |
| `service` | 服务名称（jredmine） |
| `host` | 主机名 |
| `env` | 环境（dev/local/prod） |
| `stack_trace` | 异常堆栈（如有） |

## 五、使用 MDC 添加上下文信息

### 5.1 代码示例

```java
import org.slf4j.MDC;
import lombok.extern.slf4j.Slf4j;

@Slf4j
public class UserService {
    public void login(String username, String ip) {
        // 添加上下文信息
        MDC.put("userId", "12345");
        MDC.put("username", username);
        MDC.put("ip", ip);
        
        try {
            log.info("用户登录成功");
            // ... 业务逻辑
        } finally {
            // 清理 MDC（重要：避免内存泄漏）
            MDC.clear();
        }
    }
}
```

### 5.2 MDC 最佳实践

1. **及时清理**：使用 `try-finally` 确保 MDC 被清理
2. **使用拦截器**：在 Web 拦截器中统一添加请求上下文（如 traceId、userId）
3. **避免过度使用**：只添加必要的上下文信息

## 六、日志文件管理

### 6.1 日志文件位置

默认日志目录：`logs/`（项目根目录）

可通过环境变量 `LOG_HOME` 自定义：
```bash
export LOG_HOME=/var/log/jredmine
```

### 6.2 日志文件结构

```
logs/
├── jredmine.log              # 当前日志文件
├── jredmine-2024-01-14.0.log.gz  # 历史日志（已压缩）
├── jredmine-2024-01-14.1.log.gz
├── jredmine-error.log        # 当前错误日志
└── jredmine-error-2024-01-14.0.log.gz  # 历史错误日志
```

### 6.3 日志清理

- 自动清理：启动时自动清理过期日志
- 手动清理：删除 `logs/` 目录下的 `.gz` 文件

## 七、环境变量配置

### 7.1 可配置的环境变量

| 变量名 | 说明 | 默认值 |
|--------|------|--------|
| `LOG_HOME` | 日志文件存储目录 | `logs` |
| `HOSTNAME` | 主机名 | `unknown` |
| `spring.profiles.active` | Spring 环境配置 | 从 `application.yml` 读取 |

### 7.2 启动时指定

```bash
# 指定日志目录
export LOG_HOME=/var/log/jredmine

# 指定环境
java -jar jredmine.jar --spring.profiles.active=prod

# 或使用环境变量
SPRING_PROFILES_ACTIVE=prod java -jar jredmine.jar
```

## 八、日志收集集成

### 8.1 ELK Stack（Elasticsearch + Logstash + Kibana）

日志文件已经是 JSON 格式，可以直接被 Logstash 收集：

```ruby
# logstash.conf
input {
  file {
    path => "/path/to/logs/jredmine*.log"
    codec => "json"
  }
}

output {
  elasticsearch {
    hosts => ["localhost:9200"]
    index => "jredmine-%{+YYYY.MM.dd}"
  }
}
```

### 8.2 Loki（Grafana Loki）

使用 Promtail 收集日志：

```yaml
# promtail-config.yaml
server:
  http_listen_port: 9080

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
  - job_name: jredmine
    static_configs:
      - targets:
          - localhost
        labels:
          job: jredmine
          __path__: /path/to/logs/jredmine*.log
```

## 九、性能优化建议

### 9.1 已实现的优化

1. ✅ 异步日志输出（AsyncAppender）
2. ✅ 日志文件压缩（gzip）
3. ✅ 日志文件滚动（按大小和日期）

### 9.2 可选的进一步优化

1. **调整异步队列大小**：
   ```xml
   <queueSize>1024</queueSize>  <!-- 根据日志量调整 -->
   ```

2. **使用 Lazy Evaluation**：
   ```java
   log.debug("复杂计算: {}", () -> expensiveOperation());
   ```

3. **生产环境关闭控制台输出**（如果使用日志收集系统）：
   ```xml
   <springProfile name="prod">
       <root level="INFO">
           <!-- 移除 CONSOLE appender -->
           <appender-ref ref="ASYNC_FILE"/>
           <appender-ref ref="ASYNC_ERROR_FILE"/>
       </root>
   </springProfile>
   ```

## 十、常见问题

### 10.1 日志文件未生成

**原因**：
- 日志目录权限不足
- 环境变量 `LOG_HOME` 配置错误

**解决**：
```bash
# 检查目录权限
mkdir -p logs
chmod 755 logs

# 检查环境变量
echo $LOG_HOME
```

### 10.2 日志格式不是 JSON

**原因**：
- 使用了错误的 Spring Profile
- `logback-spring.xml` 配置未生效

**解决**：
```bash
# 确认环境配置
java -jar app.jar --spring.profiles.active=prod

# 检查配置文件位置
ls -la src/main/resources/logback-spring.xml
```

### 10.3 日志文件过大

**原因**：
- 日志级别配置过低（如 DEBUG）
- 日志滚动配置不合理

**解决**：
- 生产环境使用 INFO 级别
- 调整 `maxFileSize` 和 `maxHistory`

## 十一、配置验证

### 11.1 验证日志配置

启动应用后，检查：

1. **日志文件是否生成**：
   ```bash
   ls -lh logs/
   ```

2. **日志格式是否正确**：
   ```bash
   head -1 logs/jredmine.log | jq .
   ```

3. **日志级别是否正确**：
   ```bash
   # 查看日志级别分布
   grep -o '"level":"[^"]*"' logs/jredmine.log | sort | uniq -c
   ```

### 11.2 测试日志输出

```java
@Slf4j
@RestController
public class LogTestController {
    @GetMapping("/test/log")
    public String testLog() {
        MDC.put("testKey", "testValue");
        log.info("测试日志输出");
        log.debug("这是 DEBUG 日志");
        log.warn("这是 WARN 日志");
        log.error("这是 ERROR 日志");
        MDC.clear();
        return "日志已输出，请查看 logs/ 目录";
    }
}
```

---

**文档创建时间**：2024-01-15  
**适用版本**：Spring Boot 3.0.4, Logback, Logstash Encoder 7.4

